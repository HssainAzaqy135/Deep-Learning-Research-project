{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bac7d2-14d0-4c4d-85d2-cd536f776bec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d0d813-f1b5-489b-b667-84c583211908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchensemble import VotingClassifier\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "# Extras\n",
    "import time\n",
    "import os\n",
    "# Torch Ensemble imports\n",
    "from torchensemble import VotingClassifier  # voting is a classic ensemble strategy\n",
    "from torchensemble.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baacb393-ebf0-4e22-9b90-759653e1fb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params\n",
    "# Set training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "epochs = 30\n",
    "\n",
    "base_estimator = nn.Sequential(\n",
    "    nn.Flatten(),            # Flatten the 28x28 input images to a vector of 784\n",
    "    nn.Linear(28 * 28, 256), # First fully connected layer\n",
    "    nn.ReLU(),               # Activation function\n",
    "    nn.Linear(256, 128),     # Second fully connected layer\n",
    "    nn.ReLU(),               # Activation function\n",
    "    nn.Linear(128, 10)       # Output layer for 10 classes\n",
    ")\n",
    "# If using GPU, transfer data to the GPU inside fit() and evaluate() loops\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Set the base estimator to the device\n",
    "base_estimator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e61f523-a77f-42ce-be1a-b12d7fe668db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize using MNIST mean and std\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Number of samples per class\n",
    "samples_per_class = 2000\n",
    "\n",
    "# Get all targets\n",
    "all_targets = train_dataset.targets.numpy()\n",
    "\n",
    "# Initialize list to store indices\n",
    "subset_indices = []\n",
    "\n",
    "# For each class, get the first 'samples_per_class' indices\n",
    "for class_label in range(10):  # MNIST has 10 classes\n",
    "    class_indices = np.where(all_targets == class_label)[0][:samples_per_class]\n",
    "    subset_indices.extend(class_indices)\n",
    "\n",
    "# Create the subset\n",
    "balanced_subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "# Create a DataLoader for the balanced subset\n",
    "balanced_training_loader = DataLoader(balanced_subset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ea7cb1-776c-49f3-9bd7-73d3f0fbfdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total= 0\n",
    "for batch in balanced_training_loader:\n",
    "    total+=len(batch[0])\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f67196-2288-49f8-ab46-6b9b4ec8571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimator=base_estimator,  # here is your deep learning model\n",
    "    n_estimators=5,           # number of base estimators\n",
    "    cuda=torch.cuda.is_available(),  # Enable GPU if available\n",
    ")\n",
    "\n",
    "# Set the criterion\n",
    "criterion = nn.CrossEntropyLoss()  # training objective\n",
    "ensemble.set_criterion(criterion)\n",
    "\n",
    "# Set the optimizer\n",
    "ensemble.set_optimizer(\n",
    "    \"Adam\",                       # type of parameter optimizer\n",
    "    lr=learning_rate,             # learning rate of parameter optimizer\n",
    "    weight_decay=weight_decay,    # weight decay of parameter optimizer\n",
    ")\n",
    "\n",
    "# Set the learning rate scheduler\n",
    "ensemble.set_scheduler(\n",
    "    \"CosineAnnealingLR\",          # type of learning rate scheduler\n",
    "    T_max=epochs,                 # number of epochs for decay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ffce6-ae45-43eb-b7d2-3ce50c015afc",
   "metadata": {},
   "source": [
    "# Train the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ba9f07-21eb-4286-ada2-775a5bf7f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.30704 | Correct: 6/64\n",
      "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.31013 | Correct: 58/64\n",
      "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 0.27953 | Correct: 60/64\n",
      "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 0.19611 | Correct: 61/64\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.29103 | Correct: 9/64\n",
      "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.27512 | Correct: 60/64\n",
      "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 0.39145 | Correct: 57/64\n",
      "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 0.18276 | Correct: 61/64\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.29860 | Correct: 6/64\n",
      "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.28493 | Correct: 58/64\n",
      "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 0.17019 | Correct: 62/64\n",
      "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 0.31302 | Correct: 59/64\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.30110 | Correct: 6/64\n",
      "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.28496 | Correct: 58/64\n",
      "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 0.23363 | Correct: 60/64\n",
      "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 0.17394 | Correct: 58/64\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 2.28347 | Correct: 5/64\n",
      "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 0.39521 | Correct: 57/64\n",
      "Estimator: 004 | Epoch: 000 | Batch: 200 | Loss: 0.19141 | Correct: 59/64\n",
      "Estimator: 004 | Epoch: 000 | Batch: 300 | Loss: 0.18981 | Correct: 61/64\n",
      "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.13929 | Correct: 61/64\n",
      "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.16942 | Correct: 61/64\n",
      "Estimator: 000 | Epoch: 001 | Batch: 200 | Loss: 0.27973 | Correct: 61/64\n",
      "Estimator: 000 | Epoch: 001 | Batch: 300 | Loss: 0.18438 | Correct: 59/64\n",
      "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.20266 | Correct: 59/64\n",
      "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.13957 | Correct: 61/64\n",
      "Estimator: 001 | Epoch: 001 | Batch: 200 | Loss: 0.25187 | Correct: 61/64\n",
      "Estimator: 001 | Epoch: 001 | Batch: 300 | Loss: 0.07774 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.14069 | Correct: 61/64\n",
      "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.24384 | Correct: 58/64\n",
      "Estimator: 002 | Epoch: 001 | Batch: 200 | Loss: 0.07593 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 001 | Batch: 300 | Loss: 0.09148 | Correct: 61/64\n",
      "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.23794 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.11099 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 001 | Batch: 200 | Loss: 0.05553 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 001 | Batch: 300 | Loss: 0.33216 | Correct: 61/64\n",
      "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 0.17802 | Correct: 62/64\n",
      "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 0.06841 | Correct: 62/64\n",
      "Estimator: 004 | Epoch: 001 | Batch: 200 | Loss: 0.11725 | Correct: 60/64\n",
      "Estimator: 004 | Epoch: 001 | Batch: 300 | Loss: 0.19764 | Correct: 60/64\n",
      "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.08872 | Correct: 62/64\n",
      "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.13175 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 002 | Batch: 200 | Loss: 0.04154 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 002 | Batch: 300 | Loss: 0.16569 | Correct: 62/64\n",
      "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.05241 | Correct: 62/64\n",
      "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.14450 | Correct: 60/64\n",
      "Estimator: 001 | Epoch: 002 | Batch: 200 | Loss: 0.07926 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 002 | Batch: 300 | Loss: 0.22541 | Correct: 59/64\n",
      "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.04483 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.15399 | Correct: 60/64\n",
      "Estimator: 002 | Epoch: 002 | Batch: 200 | Loss: 0.11023 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 002 | Batch: 300 | Loss: 0.05084 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.05725 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.04345 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 002 | Batch: 200 | Loss: 0.21026 | Correct: 59/64\n",
      "Estimator: 003 | Epoch: 002 | Batch: 300 | Loss: 0.06909 | Correct: 62/64\n",
      "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 0.12368 | Correct: 61/64\n",
      "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 0.04124 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 002 | Batch: 200 | Loss: 0.07828 | Correct: 62/64\n",
      "Estimator: 004 | Epoch: 002 | Batch: 300 | Loss: 0.11523 | Correct: 62/64\n",
      "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.05618 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.05936 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 003 | Batch: 200 | Loss: 0.06037 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 003 | Batch: 300 | Loss: 0.05720 | Correct: 62/64\n",
      "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.01378 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.03763 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 003 | Batch: 200 | Loss: 0.06155 | Correct: 62/64\n",
      "Estimator: 001 | Epoch: 003 | Batch: 300 | Loss: 0.02182 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.06693 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.04538 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 003 | Batch: 200 | Loss: 0.03456 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 003 | Batch: 300 | Loss: 0.07298 | Correct: 61/64\n",
      "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.13821 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.01809 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 003 | Batch: 200 | Loss: 0.01666 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 003 | Batch: 300 | Loss: 0.00467 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 0.01076 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 0.03937 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 003 | Batch: 200 | Loss: 0.06726 | Correct: 62/64\n",
      "Estimator: 004 | Epoch: 003 | Batch: 300 | Loss: 0.05464 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.01814 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.11915 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 004 | Batch: 200 | Loss: 0.08770 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 004 | Batch: 300 | Loss: 0.03573 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.07367 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.01002 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 004 | Batch: 200 | Loss: 0.11971 | Correct: 62/64\n",
      "Estimator: 001 | Epoch: 004 | Batch: 300 | Loss: 0.05322 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.04706 | Correct: 62/64\n",
      "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.05124 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 004 | Batch: 200 | Loss: 0.02143 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 004 | Batch: 300 | Loss: 0.04639 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.04985 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.03477 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 004 | Batch: 200 | Loss: 0.04608 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 004 | Batch: 300 | Loss: 0.02895 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 0.02516 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 0.02975 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 004 | Batch: 200 | Loss: 0.16097 | Correct: 62/64\n",
      "Estimator: 004 | Epoch: 004 | Batch: 300 | Loss: 0.03533 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 0.03208 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 005 | Batch: 100 | Loss: 0.04033 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 005 | Batch: 200 | Loss: 0.02668 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 005 | Batch: 300 | Loss: 0.01869 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 0.02918 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 005 | Batch: 100 | Loss: 0.01975 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 005 | Batch: 200 | Loss: 0.02248 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 005 | Batch: 300 | Loss: 0.02583 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 0.02938 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 005 | Batch: 100 | Loss: 0.00638 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 005 | Batch: 200 | Loss: 0.03076 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 005 | Batch: 300 | Loss: 0.04709 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 0.06711 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 005 | Batch: 100 | Loss: 0.00204 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 005 | Batch: 200 | Loss: 0.05624 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 005 | Batch: 300 | Loss: 0.02267 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 005 | Batch: 000 | Loss: 0.01487 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 005 | Batch: 100 | Loss: 0.02452 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 005 | Batch: 200 | Loss: 0.01367 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 005 | Batch: 300 | Loss: 0.02095 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 0.08043 | Correct: 62/64\n",
      "Estimator: 000 | Epoch: 006 | Batch: 100 | Loss: 0.00426 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 006 | Batch: 200 | Loss: 0.02674 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 006 | Batch: 300 | Loss: 0.00972 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 0.00857 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 006 | Batch: 100 | Loss: 0.03143 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 006 | Batch: 200 | Loss: 0.00783 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 006 | Batch: 300 | Loss: 0.01028 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 0.00454 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 006 | Batch: 100 | Loss: 0.01994 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 006 | Batch: 200 | Loss: 0.00120 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 006 | Batch: 300 | Loss: 0.02289 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 0.00708 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 006 | Batch: 100 | Loss: 0.01457 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 006 | Batch: 200 | Loss: 0.05769 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 006 | Batch: 300 | Loss: 0.01552 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 006 | Batch: 000 | Loss: 0.01609 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 006 | Batch: 100 | Loss: 0.02540 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 006 | Batch: 200 | Loss: 0.06011 | Correct: 61/64\n",
      "Estimator: 004 | Epoch: 006 | Batch: 300 | Loss: 0.02743 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 0.03368 | Correct: 62/64\n",
      "Estimator: 000 | Epoch: 007 | Batch: 100 | Loss: 0.02326 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 007 | Batch: 200 | Loss: 0.04915 | Correct: 62/64\n",
      "Estimator: 000 | Epoch: 007 | Batch: 300 | Loss: 0.08808 | Correct: 61/64\n",
      "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 0.01320 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 007 | Batch: 100 | Loss: 0.00917 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 007 | Batch: 200 | Loss: 0.00276 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 007 | Batch: 300 | Loss: 0.01279 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 0.08169 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 007 | Batch: 100 | Loss: 0.01865 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 007 | Batch: 200 | Loss: 0.00355 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 007 | Batch: 300 | Loss: 0.04623 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 0.02368 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 007 | Batch: 100 | Loss: 0.00481 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 007 | Batch: 200 | Loss: 0.03614 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 007 | Batch: 300 | Loss: 0.00308 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 007 | Batch: 000 | Loss: 0.06288 | Correct: 61/64\n",
      "Estimator: 004 | Epoch: 007 | Batch: 100 | Loss: 0.00795 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 007 | Batch: 200 | Loss: 0.00336 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 007 | Batch: 300 | Loss: 0.00992 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 0.00226 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 008 | Batch: 100 | Loss: 0.00133 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 008 | Batch: 200 | Loss: 0.00270 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 008 | Batch: 300 | Loss: 0.01571 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 0.01987 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 008 | Batch: 100 | Loss: 0.00403 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 008 | Batch: 200 | Loss: 0.00429 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 008 | Batch: 300 | Loss: 0.03761 | Correct: 62/64\n",
      "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 0.00849 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 008 | Batch: 100 | Loss: 0.02295 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 008 | Batch: 200 | Loss: 0.01893 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 008 | Batch: 300 | Loss: 0.00263 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 0.00073 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 008 | Batch: 100 | Loss: 0.00414 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 008 | Batch: 200 | Loss: 0.05379 | Correct: 62/64\n",
      "Estimator: 003 | Epoch: 008 | Batch: 300 | Loss: 0.03448 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 008 | Batch: 000 | Loss: 0.00919 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 008 | Batch: 100 | Loss: 0.00318 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 008 | Batch: 200 | Loss: 0.00280 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 008 | Batch: 300 | Loss: 0.01545 | Correct: 63/64\n",
      "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 0.00298 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 009 | Batch: 100 | Loss: 0.00994 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 009 | Batch: 200 | Loss: 0.00676 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 009 | Batch: 300 | Loss: 0.00191 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 0.01027 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 009 | Batch: 100 | Loss: 0.00188 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 009 | Batch: 200 | Loss: 0.03500 | Correct: 63/64\n",
      "Estimator: 001 | Epoch: 009 | Batch: 300 | Loss: 0.00537 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 0.02213 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 009 | Batch: 100 | Loss: 0.00700 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 009 | Batch: 200 | Loss: 0.01864 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 009 | Batch: 300 | Loss: 0.01752 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 0.00284 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 009 | Batch: 100 | Loss: 0.00090 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 009 | Batch: 200 | Loss: 0.00728 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 009 | Batch: 300 | Loss: 0.00494 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 009 | Batch: 000 | Loss: 0.02533 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 009 | Batch: 100 | Loss: 0.00168 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 009 | Batch: 200 | Loss: 0.01677 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 009 | Batch: 300 | Loss: 0.00989 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 010 | Batch: 000 | Loss: 0.00150 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 010 | Batch: 100 | Loss: 0.00138 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 010 | Batch: 200 | Loss: 0.00245 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 010 | Batch: 300 | Loss: 0.00857 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 010 | Batch: 000 | Loss: 0.00514 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 010 | Batch: 100 | Loss: 0.00104 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 010 | Batch: 200 | Loss: 0.00911 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 010 | Batch: 300 | Loss: 0.00584 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 010 | Batch: 000 | Loss: 0.00619 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 010 | Batch: 100 | Loss: 0.02269 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 010 | Batch: 200 | Loss: 0.00840 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 010 | Batch: 300 | Loss: 0.01408 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 010 | Batch: 000 | Loss: 0.00295 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 010 | Batch: 100 | Loss: 0.01647 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 010 | Batch: 200 | Loss: 0.00297 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 010 | Batch: 300 | Loss: 0.00616 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 010 | Batch: 000 | Loss: 0.02452 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 010 | Batch: 100 | Loss: 0.02358 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 010 | Batch: 200 | Loss: 0.00213 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 010 | Batch: 300 | Loss: 0.00124 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 011 | Batch: 000 | Loss: 0.00171 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 011 | Batch: 100 | Loss: 0.00214 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 011 | Batch: 200 | Loss: 0.00238 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 011 | Batch: 300 | Loss: 0.00150 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 011 | Batch: 000 | Loss: 0.00281 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 011 | Batch: 100 | Loss: 0.00413 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 011 | Batch: 200 | Loss: 0.00200 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 011 | Batch: 300 | Loss: 0.03592 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 011 | Batch: 000 | Loss: 0.03005 | Correct: 63/64\n",
      "Estimator: 002 | Epoch: 011 | Batch: 100 | Loss: 0.00884 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 011 | Batch: 200 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 011 | Batch: 300 | Loss: 0.02536 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 011 | Batch: 000 | Loss: 0.00218 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 011 | Batch: 100 | Loss: 0.04092 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 011 | Batch: 200 | Loss: 0.00120 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 011 | Batch: 300 | Loss: 0.00653 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 011 | Batch: 000 | Loss: 0.00403 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 011 | Batch: 100 | Loss: 0.05761 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 011 | Batch: 200 | Loss: 0.05029 | Correct: 63/64\n",
      "Estimator: 004 | Epoch: 011 | Batch: 300 | Loss: 0.00960 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 012 | Batch: 000 | Loss: 0.00034 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 012 | Batch: 100 | Loss: 0.01226 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 012 | Batch: 200 | Loss: 0.04390 | Correct: 62/64\n",
      "Estimator: 000 | Epoch: 012 | Batch: 300 | Loss: 0.02152 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 012 | Batch: 000 | Loss: 0.00235 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 012 | Batch: 100 | Loss: 0.00135 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 012 | Batch: 200 | Loss: 0.00287 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 012 | Batch: 300 | Loss: 0.00076 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 012 | Batch: 000 | Loss: 0.00962 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 012 | Batch: 100 | Loss: 0.00081 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 012 | Batch: 200 | Loss: 0.00449 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 012 | Batch: 300 | Loss: 0.00051 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 012 | Batch: 000 | Loss: 0.00536 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 012 | Batch: 100 | Loss: 0.04574 | Correct: 63/64\n",
      "Estimator: 003 | Epoch: 012 | Batch: 200 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 012 | Batch: 300 | Loss: 0.00190 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 012 | Batch: 000 | Loss: 0.00093 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 012 | Batch: 100 | Loss: 0.00322 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 012 | Batch: 200 | Loss: 0.00137 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 012 | Batch: 300 | Loss: 0.00167 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 013 | Batch: 000 | Loss: 0.00759 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 013 | Batch: 100 | Loss: 0.00068 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 013 | Batch: 200 | Loss: 0.00118 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 013 | Batch: 300 | Loss: 0.00603 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 013 | Batch: 000 | Loss: 0.00125 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 013 | Batch: 100 | Loss: 0.00448 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 013 | Batch: 200 | Loss: 0.00227 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 013 | Batch: 300 | Loss: 0.00456 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 013 | Batch: 000 | Loss: 0.00096 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 013 | Batch: 100 | Loss: 0.00079 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 013 | Batch: 200 | Loss: 0.00256 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 013 | Batch: 300 | Loss: 0.00032 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 013 | Batch: 000 | Loss: 0.00055 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 013 | Batch: 100 | Loss: 0.00078 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 013 | Batch: 200 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 013 | Batch: 300 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 013 | Batch: 000 | Loss: 0.00112 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 013 | Batch: 100 | Loss: 0.00105 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 013 | Batch: 200 | Loss: 0.00033 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 013 | Batch: 300 | Loss: 0.00042 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 014 | Batch: 000 | Loss: 0.00189 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 014 | Batch: 100 | Loss: 0.00052 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 014 | Batch: 200 | Loss: 0.00201 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 014 | Batch: 300 | Loss: 0.00028 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 014 | Batch: 000 | Loss: 0.00069 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 014 | Batch: 100 | Loss: 0.00112 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 014 | Batch: 200 | Loss: 0.00013 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 014 | Batch: 300 | Loss: 0.00052 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 014 | Batch: 000 | Loss: 0.00074 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 014 | Batch: 100 | Loss: 0.00072 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 014 | Batch: 200 | Loss: 0.00003 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 014 | Batch: 300 | Loss: 0.00049 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 014 | Batch: 000 | Loss: 0.00074 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 014 | Batch: 100 | Loss: 0.00008 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 014 | Batch: 200 | Loss: 0.00109 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 014 | Batch: 300 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 014 | Batch: 000 | Loss: 0.00028 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 014 | Batch: 100 | Loss: 0.00073 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 014 | Batch: 200 | Loss: 0.00036 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 014 | Batch: 300 | Loss: 0.00053 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 015 | Batch: 000 | Loss: 0.00030 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 015 | Batch: 100 | Loss: 0.00143 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 015 | Batch: 200 | Loss: 0.00034 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 015 | Batch: 300 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 015 | Batch: 000 | Loss: 0.00075 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 015 | Batch: 100 | Loss: 0.00072 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 015 | Batch: 200 | Loss: 0.00070 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 015 | Batch: 300 | Loss: 0.00032 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 015 | Batch: 000 | Loss: 0.00073 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 015 | Batch: 100 | Loss: 0.00021 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 015 | Batch: 200 | Loss: 0.00034 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 015 | Batch: 300 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 015 | Batch: 000 | Loss: 0.00055 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 015 | Batch: 100 | Loss: 0.00075 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 015 | Batch: 200 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 015 | Batch: 300 | Loss: 0.00069 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 015 | Batch: 000 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 015 | Batch: 100 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 015 | Batch: 200 | Loss: 0.00021 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 015 | Batch: 300 | Loss: 0.00228 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 016 | Batch: 000 | Loss: 0.00047 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 016 | Batch: 100 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 016 | Batch: 200 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 016 | Batch: 300 | Loss: 0.00050 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 016 | Batch: 000 | Loss: 0.00029 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 016 | Batch: 100 | Loss: 0.00052 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 016 | Batch: 200 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 016 | Batch: 300 | Loss: 0.00123 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 016 | Batch: 000 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 016 | Batch: 100 | Loss: 0.00065 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 016 | Batch: 200 | Loss: 0.00016 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 016 | Batch: 300 | Loss: 0.00160 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 016 | Batch: 000 | Loss: 0.00047 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 016 | Batch: 100 | Loss: 0.00014 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 016 | Batch: 200 | Loss: 0.00084 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 016 | Batch: 300 | Loss: 0.00070 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 016 | Batch: 000 | Loss: 0.00091 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 016 | Batch: 100 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 016 | Batch: 200 | Loss: 0.00135 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 016 | Batch: 300 | Loss: 0.00065 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 017 | Batch: 000 | Loss: 0.00068 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 017 | Batch: 100 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 017 | Batch: 200 | Loss: 0.00064 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 017 | Batch: 300 | Loss: 0.00067 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 017 | Batch: 000 | Loss: 0.00096 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 017 | Batch: 100 | Loss: 0.00051 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 017 | Batch: 200 | Loss: 0.00019 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 017 | Batch: 300 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 017 | Batch: 000 | Loss: 0.00050 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 017 | Batch: 100 | Loss: 0.00029 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 017 | Batch: 200 | Loss: 0.00022 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 017 | Batch: 300 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 017 | Batch: 000 | Loss: 0.00031 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 017 | Batch: 100 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 017 | Batch: 200 | Loss: 0.00057 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 017 | Batch: 300 | Loss: 0.00026 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 017 | Batch: 000 | Loss: 0.00004 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 017 | Batch: 100 | Loss: 0.00026 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 017 | Batch: 200 | Loss: 0.00081 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 017 | Batch: 300 | Loss: 0.00088 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 018 | Batch: 000 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 018 | Batch: 100 | Loss: 0.00046 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 018 | Batch: 200 | Loss: 0.00031 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 018 | Batch: 300 | Loss: 0.00067 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 018 | Batch: 000 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 018 | Batch: 100 | Loss: 0.00031 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 018 | Batch: 200 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 018 | Batch: 300 | Loss: 0.00056 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 018 | Batch: 000 | Loss: 0.00073 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 018 | Batch: 100 | Loss: 0.00071 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 018 | Batch: 200 | Loss: 0.00038 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 018 | Batch: 300 | Loss: 0.00096 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 018 | Batch: 000 | Loss: 0.00027 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 018 | Batch: 100 | Loss: 0.00011 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 018 | Batch: 200 | Loss: 0.00043 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 018 | Batch: 300 | Loss: 0.00100 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 018 | Batch: 000 | Loss: 0.00125 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 018 | Batch: 100 | Loss: 0.00032 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 018 | Batch: 200 | Loss: 0.00033 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 018 | Batch: 300 | Loss: 0.00027 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 019 | Batch: 000 | Loss: 0.00017 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 019 | Batch: 100 | Loss: 0.00016 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 019 | Batch: 200 | Loss: 0.00062 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 019 | Batch: 300 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 019 | Batch: 000 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 019 | Batch: 100 | Loss: 0.00055 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 019 | Batch: 200 | Loss: 0.00143 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 019 | Batch: 300 | Loss: 0.00104 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 019 | Batch: 000 | Loss: 0.00068 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 019 | Batch: 100 | Loss: 0.00061 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 019 | Batch: 200 | Loss: 0.00067 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 019 | Batch: 300 | Loss: 0.00206 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 019 | Batch: 000 | Loss: 0.00082 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 019 | Batch: 100 | Loss: 0.00030 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 019 | Batch: 200 | Loss: 0.00026 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 019 | Batch: 300 | Loss: 0.00051 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 019 | Batch: 000 | Loss: 0.00040 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 019 | Batch: 100 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 019 | Batch: 200 | Loss: 0.00026 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 019 | Batch: 300 | Loss: 0.00074 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 020 | Batch: 000 | Loss: 0.00064 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 020 | Batch: 100 | Loss: 0.00024 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 020 | Batch: 200 | Loss: 0.00079 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 020 | Batch: 300 | Loss: 0.00102 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 020 | Batch: 000 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 020 | Batch: 100 | Loss: 0.00075 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 020 | Batch: 200 | Loss: 0.00064 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 020 | Batch: 300 | Loss: 0.00115 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 020 | Batch: 000 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 020 | Batch: 100 | Loss: 0.00103 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 020 | Batch: 200 | Loss: 0.00057 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 020 | Batch: 300 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 020 | Batch: 000 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 020 | Batch: 100 | Loss: 0.00043 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 020 | Batch: 200 | Loss: 0.00036 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 020 | Batch: 300 | Loss: 0.00070 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 020 | Batch: 000 | Loss: 0.00015 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 020 | Batch: 100 | Loss: 0.00071 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 020 | Batch: 200 | Loss: 0.00076 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 020 | Batch: 300 | Loss: 0.00074 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 021 | Batch: 000 | Loss: 0.00045 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 021 | Batch: 100 | Loss: 0.00105 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 021 | Batch: 200 | Loss: 0.00049 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 021 | Batch: 300 | Loss: 0.00034 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 021 | Batch: 000 | Loss: 0.00087 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 021 | Batch: 100 | Loss: 0.00063 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 021 | Batch: 200 | Loss: 0.00064 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 021 | Batch: 300 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 021 | Batch: 000 | Loss: 0.00102 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 021 | Batch: 100 | Loss: 0.00124 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 021 | Batch: 200 | Loss: 0.00018 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 021 | Batch: 300 | Loss: 0.00145 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 021 | Batch: 000 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 021 | Batch: 100 | Loss: 0.00106 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 021 | Batch: 200 | Loss: 0.00055 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 021 | Batch: 300 | Loss: 0.00101 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 021 | Batch: 000 | Loss: 0.00062 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 021 | Batch: 100 | Loss: 0.00096 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 021 | Batch: 200 | Loss: 0.00079 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 021 | Batch: 300 | Loss: 0.00127 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 022 | Batch: 000 | Loss: 0.00022 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 022 | Batch: 100 | Loss: 0.00020 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 022 | Batch: 200 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 022 | Batch: 300 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 022 | Batch: 000 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 022 | Batch: 100 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 022 | Batch: 200 | Loss: 0.00112 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 022 | Batch: 300 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 022 | Batch: 000 | Loss: 0.00101 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 022 | Batch: 100 | Loss: 0.00045 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 022 | Batch: 200 | Loss: 0.00112 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 022 | Batch: 300 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 022 | Batch: 000 | Loss: 0.00042 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 022 | Batch: 100 | Loss: 0.00052 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 022 | Batch: 200 | Loss: 0.00135 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 022 | Batch: 300 | Loss: 0.00121 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 022 | Batch: 000 | Loss: 0.00136 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 022 | Batch: 100 | Loss: 0.00061 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 022 | Batch: 200 | Loss: 0.00100 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 022 | Batch: 300 | Loss: 0.00031 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 023 | Batch: 000 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 023 | Batch: 100 | Loss: 0.00074 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 023 | Batch: 200 | Loss: 0.00098 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 023 | Batch: 300 | Loss: 0.00026 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 023 | Batch: 000 | Loss: 0.00080 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 023 | Batch: 100 | Loss: 0.00097 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 023 | Batch: 200 | Loss: 0.00124 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 023 | Batch: 300 | Loss: 0.00085 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 023 | Batch: 000 | Loss: 0.00079 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 023 | Batch: 100 | Loss: 0.00099 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 023 | Batch: 200 | Loss: 0.00040 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 023 | Batch: 300 | Loss: 0.00071 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 023 | Batch: 000 | Loss: 0.00046 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 023 | Batch: 100 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 023 | Batch: 200 | Loss: 0.00075 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 023 | Batch: 300 | Loss: 0.00077 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 023 | Batch: 000 | Loss: 0.00062 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 023 | Batch: 100 | Loss: 0.00089 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 023 | Batch: 200 | Loss: 0.00071 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 023 | Batch: 300 | Loss: 0.00095 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 024 | Batch: 000 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 024 | Batch: 100 | Loss: 0.00033 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 024 | Batch: 200 | Loss: 0.00115 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 024 | Batch: 300 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 024 | Batch: 000 | Loss: 0.00106 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 024 | Batch: 100 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 024 | Batch: 200 | Loss: 0.00046 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 024 | Batch: 300 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 024 | Batch: 000 | Loss: 0.00106 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 024 | Batch: 100 | Loss: 0.00116 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 024 | Batch: 200 | Loss: 0.00031 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 024 | Batch: 300 | Loss: 0.00022 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 024 | Batch: 000 | Loss: 0.00075 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 024 | Batch: 100 | Loss: 0.00099 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 024 | Batch: 200 | Loss: 0.00068 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 024 | Batch: 300 | Loss: 0.00059 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 024 | Batch: 000 | Loss: 0.00043 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 024 | Batch: 100 | Loss: 0.00080 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 024 | Batch: 200 | Loss: 0.00082 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 024 | Batch: 300 | Loss: 0.00072 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 025 | Batch: 000 | Loss: 0.00046 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 025 | Batch: 100 | Loss: 0.00043 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 025 | Batch: 200 | Loss: 0.00135 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 025 | Batch: 300 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 025 | Batch: 000 | Loss: 0.00058 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 025 | Batch: 100 | Loss: 0.00046 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 025 | Batch: 200 | Loss: 0.00032 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 025 | Batch: 300 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 025 | Batch: 000 | Loss: 0.00020 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 025 | Batch: 100 | Loss: 0.00110 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 025 | Batch: 200 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 025 | Batch: 300 | Loss: 0.00089 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 025 | Batch: 000 | Loss: 0.00045 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 025 | Batch: 100 | Loss: 0.00089 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 025 | Batch: 200 | Loss: 0.00053 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 025 | Batch: 300 | Loss: 0.00116 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 025 | Batch: 000 | Loss: 0.00045 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 025 | Batch: 100 | Loss: 0.00044 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 025 | Batch: 200 | Loss: 0.00053 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 025 | Batch: 300 | Loss: 0.00105 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 026 | Batch: 000 | Loss: 0.00144 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 026 | Batch: 100 | Loss: 0.00025 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 026 | Batch: 200 | Loss: 0.00042 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 026 | Batch: 300 | Loss: 0.00098 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 026 | Batch: 000 | Loss: 0.00088 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 026 | Batch: 100 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 026 | Batch: 200 | Loss: 0.00093 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 026 | Batch: 300 | Loss: 0.00094 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 026 | Batch: 000 | Loss: 0.00037 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 026 | Batch: 100 | Loss: 0.00114 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 026 | Batch: 200 | Loss: 0.00114 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 026 | Batch: 300 | Loss: 0.00053 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 026 | Batch: 000 | Loss: 0.00146 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 026 | Batch: 100 | Loss: 0.00023 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 026 | Batch: 200 | Loss: 0.00121 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 026 | Batch: 300 | Loss: 0.00111 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 026 | Batch: 000 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 026 | Batch: 100 | Loss: 0.00136 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 026 | Batch: 200 | Loss: 0.00103 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 026 | Batch: 300 | Loss: 0.00057 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 027 | Batch: 000 | Loss: 0.00038 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 027 | Batch: 100 | Loss: 0.00028 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 027 | Batch: 200 | Loss: 0.00024 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 027 | Batch: 300 | Loss: 0.00077 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 027 | Batch: 000 | Loss: 0.00080 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 027 | Batch: 100 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 027 | Batch: 200 | Loss: 0.00033 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 027 | Batch: 300 | Loss: 0.00100 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 027 | Batch: 000 | Loss: 0.00128 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 027 | Batch: 100 | Loss: 0.00079 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 027 | Batch: 200 | Loss: 0.00245 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 027 | Batch: 300 | Loss: 0.00048 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 027 | Batch: 000 | Loss: 0.00041 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 027 | Batch: 100 | Loss: 0.00083 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 027 | Batch: 200 | Loss: 0.00039 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 027 | Batch: 300 | Loss: 0.00047 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 027 | Batch: 000 | Loss: 0.00032 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 027 | Batch: 100 | Loss: 0.00072 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 027 | Batch: 200 | Loss: 0.00038 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 027 | Batch: 300 | Loss: 0.00101 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 028 | Batch: 000 | Loss: 0.00039 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 028 | Batch: 100 | Loss: 0.00060 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 028 | Batch: 200 | Loss: 0.00076 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 028 | Batch: 300 | Loss: 0.00078 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 028 | Batch: 000 | Loss: 0.00129 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 028 | Batch: 100 | Loss: 0.00095 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 028 | Batch: 200 | Loss: 0.00013 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 028 | Batch: 300 | Loss: 0.00134 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 028 | Batch: 000 | Loss: 0.00067 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 028 | Batch: 100 | Loss: 0.00024 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 028 | Batch: 200 | Loss: 0.00073 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 028 | Batch: 300 | Loss: 0.00086 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 028 | Batch: 000 | Loss: 0.00040 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 028 | Batch: 100 | Loss: 0.00104 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 028 | Batch: 200 | Loss: 0.00097 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 028 | Batch: 300 | Loss: 0.00067 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 028 | Batch: 000 | Loss: 0.00043 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 028 | Batch: 100 | Loss: 0.00026 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 028 | Batch: 200 | Loss: 0.00095 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 028 | Batch: 300 | Loss: 0.00066 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 029 | Batch: 000 | Loss: 0.00031 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 029 | Batch: 100 | Loss: 0.00036 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 029 | Batch: 200 | Loss: 0.00046 | Correct: 64/64\n",
      "Estimator: 000 | Epoch: 029 | Batch: 300 | Loss: 0.00136 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 029 | Batch: 000 | Loss: 0.00071 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 029 | Batch: 100 | Loss: 0.00101 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 029 | Batch: 200 | Loss: 0.00020 | Correct: 64/64\n",
      "Estimator: 001 | Epoch: 029 | Batch: 300 | Loss: 0.00067 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 029 | Batch: 000 | Loss: 0.00065 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 029 | Batch: 100 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 029 | Batch: 200 | Loss: 0.00095 | Correct: 64/64\n",
      "Estimator: 002 | Epoch: 029 | Batch: 300 | Loss: 0.00080 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 029 | Batch: 000 | Loss: 0.00104 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 029 | Batch: 100 | Loss: 0.00078 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 029 | Batch: 200 | Loss: 0.00054 | Correct: 64/64\n",
      "Estimator: 003 | Epoch: 029 | Batch: 300 | Loss: 0.00053 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 029 | Batch: 000 | Loss: 0.00077 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 029 | Batch: 100 | Loss: 0.00049 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 029 | Batch: 200 | Loss: 0.00175 | Correct: 64/64\n",
      "Estimator: 004 | Epoch: 029 | Batch: 300 | Loss: 0.00092 | Correct: 64/64\n",
      "Time taken: 465.127 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ensemble.fit(\n",
    "    balanced_training_loader,\n",
    "    epochs=epochs\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a137430-73a2-42f7-9df0-e2ae94d5c663",
   "metadata": {},
   "source": [
    "# Saving and Loading Trained Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85914aff-825f-44ca-9f5b-eadaa1e6c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ensemble_model is already fitted\n",
    "save_dir = 'Trained_models/'\n",
    "model_filename = \"VotingClassifier_Sequential_3_ckpt.pth\"\n",
    "save_path = os.path.join(save_dir, model_filename)\n",
    "\n",
    "# Save model state dict\n",
    "torch.save(ensemble.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48621dc-28e1-43a9-9ae8-d27e69ca3d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model with the same configuration as the original\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=3,\n",
    "    cuda=True\n",
    ")\n",
    "\n",
    "# Load the saved state dict into the model\n",
    "save_dir = 'Trained_models/'\n",
    "model_filename = \"VotingClassifier_Sequential_3_ckpt.pth\"\n",
    "load_path = os.path.join(save_dir, model_filename)\n",
    "\n",
    "# Load model state dict\n",
    "ensemble.load_state_dict(torch.load(load_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9d2f2f-1e5a-430d-9fd8-cc302d8819ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.74%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble\n",
    "acc = ensemble.evaluate(test_loader)  # testing accuracy\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb2a8d-fddd-4d20-8084-7ca4e994b952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
